{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from PhotonicsAI.Photon import llm_api, utils\n",
    "\n",
    "load_dotenv(dotenv_path=\"../../.env\")\n",
    "df = pd.read_parquet(\"db/AMF_papers.parquet\")\n",
    "df[\"PaperEntities1\"] = None\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if row[\"N_pages\"] < 20:\n",
    "        print(idx, \"===============\")\n",
    "\n",
    "        article = df.loc[idx][\"text_full\"]\n",
    "\n",
    "        r = llm_api.papers_entity_extraction(article)\n",
    "        df.at[idx, \"PaperEntities1\"] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "\n",
    "df.to_parquet(\"db/AMF_papers.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare 4o to o1-preview and o1-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path=\"../../.env\")\n",
    "df = pd.read_parquet(\"db/AMF_papers.parquet\")\n",
    "\n",
    "idx = 223\n",
    "article = df.loc[idx][\"text_full\"]\n",
    "print(\"--> filename: \", df.loc[idx][\"filename\"])\n",
    "\n",
    "prompt = f\"\"\"Is this a single academic article, and not a dissertation or collection of papers (single_article)?\n",
    "Is the main topic of this article about integrated photonic circuits (topic_photonic)?\n",
    "If yes, find the photonic components that are used on the chip.\n",
    "Return a concise list of these photonic components, if any (components_list).\n",
    "For each component, try to extract: brief spec,\n",
    "and the number of optical input (N) and output (M) ports denoted by NxM, e.g. 1x2.\n",
    "Do not parse specifications and descriptive modifiers of a component as separate components.\n",
    "Finally, is there an enough information to understand and desrcibe how the on-chip components\n",
    "are interconnected to form the photonic circuit (circuit_complete)?\n",
    "Answer in YAML following the template:\n",
    "single_article: True/False\n",
    "topic_photonic: True/False\n",
    "components_list:\n",
    "  - a 1x1 modulator with MHz speed\n",
    "  - a 1x2 component ...\n",
    "  ...\n",
    "circuit_complete: True/False\n",
    "\n",
    "INPUT_ARTICLE:\n",
    "{article}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(\"------------------- 4o: \")\n",
    "r = llm_api.call_openai(prompt, model=\"gpt-4o\")\n",
    "print(r)\n",
    "print(\"------------------- o1-preview: \")\n",
    "r = llm_api.call_openai_reasoning(prompt, model=\"o1-preview\")\n",
    "print(r)\n",
    "print(\"------------------- o1-mini: \")\n",
    "r = llm_api.call_openai_reasoning(prompt, model=\"o1-mini\")\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search PDK for components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"C:/Users/vansari/Documents/PhotonicAI\")\n",
    "sys.path.append(\"/Users/vahid/Downloads/PhotonicsAI_Project\")\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../../.env\")\n",
    "from PhotonicsAI.Photon import llm_api\n",
    "\n",
    "with open(\"../../Photon/templates.yaml\") as file:\n",
    "    templates_dict = yaml.safe_load(file)\n",
    "    templates_str = yaml.dump(templates_dict, default_flow_style=False)\n",
    "\n",
    "# adding components to templates_dict:\n",
    "db_docs = utils.search_directory_for_docstrings(\"../../KnowledgeBase/DesignLibrary\")\n",
    "for i in db_docs:\n",
    "    templates_dict[i[\"module_name\"]] = i[\"docstring\"]\n",
    "\n",
    "####################################\n",
    "\n",
    "df = pd.read_parquet(\"db/AMF_papers.parquet\")\n",
    "\n",
    "df[\"PaperEntities1_retrieved_components\"] = None\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if pd.notna(row[\"PaperEntities1\"]):\n",
    "        if (\n",
    "            row[\"PaperEntities1\"][\"single_article\"]\n",
    "            and row[\"PaperEntities1\"][\"topic_photonic\"]\n",
    "            and row[\"PaperEntities1\"][\"circuit_complete\"]\n",
    "        ):\n",
    "            retrieved_components = []\n",
    "            for c in row[\"PaperEntities1\"][\"components_list\"]:\n",
    "                r = llm_api.llm_search(c, list(templates_dict.values()))\n",
    "                retrieved_components.append(r.dict())\n",
    "\n",
    "            df.at[idx, \"PaperEntities1_retrieved_components\"] = retrieved_components\n",
    "\n",
    "            print(idx, \"===============\")\n",
    "            print(df.loc[idx][\"PaperEntities1_retrieved_components\"])\n",
    "\n",
    "        df.to_parquet(\"db/AMF_papers.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# counting how many papers have exact matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../../.env\")\n",
    "import yaml\n",
    "\n",
    "from PhotonicsAI.Photon import llm_api, utils\n",
    "\n",
    "with open(\"../../Photon/templates.yaml\") as file:\n",
    "    templates_dict = yaml.safe_load(file)\n",
    "    templates_str = yaml.dump(templates_dict, default_flow_style=False)\n",
    "\n",
    "# adding components to templates_dict:\n",
    "db_docs = utils.search_directory_for_docstrings(\"../../KnowledgeBase/DesignLibrary\")\n",
    "for i in db_docs:\n",
    "    templates_dict[i[\"module_name\"]] = i[\"docstring\"]\n",
    "\n",
    "templates_keys = list(templates_dict.keys())\n",
    "\n",
    "\n",
    "df = pd.read_parquet(\"db/AMF_papers.parquet\")\n",
    "# print(df.loc[80])\n",
    "\n",
    "exact_match_counts = 0\n",
    "partial_match_counts = 0\n",
    "poor_match_counts = 0\n",
    "for idx, row in df.iterrows():\n",
    "    if row[\"PaperEntities1_retrieved_components\"] is not None:\n",
    "        scores = [\n",
    "            comp[\"match_scores\"][0]\n",
    "            for comp in row[\"PaperEntities1_retrieved_components\"]\n",
    "        ]\n",
    "        comps_idx = [\n",
    "            comp[\"match_list\"][0] for comp in row[\"PaperEntities1_retrieved_components\"]\n",
    "        ]\n",
    "        # print(scores)\n",
    "        if all(item in [\"exact\"] for item in scores):\n",
    "            exact_match_counts += 1\n",
    "        if all(item in [\"exact\", \"partial\"] for item in scores):\n",
    "            partial_match_counts += 1\n",
    "        if all(item in [\"exact\", \"partial\", \"poor\"] for item in scores):\n",
    "            poor_match_counts += 1\n",
    "\n",
    "        # if any(item in ['poor'] for item in scores):\n",
    "        #     print(scores)\n",
    "        #     # print({templates_keys[i]: templates_dict[templates_keys[i]] for i in comps_idx})\n",
    "        #     print({templates_keys[i] for i in comps_idx})\n",
    "        #     print(row['PaperEntities1']['components_list'])\n",
    "        #     print('=============')\n",
    "\n",
    "        # if any(item in ['poor'] for item in scores):\n",
    "        print()\n",
    "        print(\"============================= idx:\", idx)\n",
    "        for k in range(len(row[\"PaperEntities1_retrieved_components\"])):\n",
    "            retrieved_items = row[\"PaperEntities1_retrieved_components\"][k]\n",
    "            comp_0 = [templates_keys[i] for i in retrieved_items[\"match_list\"]][0]\n",
    "            score_0 = retrieved_items[\"match_scores\"][0]\n",
    "            search_phrase = row[\"PaperEntities1\"][\"components_list\"][k]\n",
    "\n",
    "            if score_0 == \"exact\":\n",
    "                print(f\"{comp_0} ({score_0}) <-- {search_phrase}\")\n",
    "\n",
    "        # gufghgf\n",
    "\n",
    "print(\"exact_match_counts\", exact_match_counts)\n",
    "print(\"partial_match_counts\", partial_match_counts)\n",
    "print(\"poor_match_counts\", poor_match_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = \"\"\"Waveguide: Incorporates loss due to propagation, phase shift, and time delay.\"\"\"\n",
    "\n",
    "for i in range(20):\n",
    "    r = llm_api.llm_search(c, list(templates_dict.values()))\n",
    "\n",
    "    print(\"scores: \", r.match_scores)\n",
    "    print(\"components: \", [templates_keys[i] for i in r.match_list])\n",
    "    print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PhotonEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
