{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = \"db/AMF_selected\"\n",
    "pdf_files = [f for f in os.listdir(directory) if f.endswith(\".pdf\")]\n",
    "for i, filename in enumerate(pdf_files):\n",
    "    new_name = f\"{i+1:03}.pdf\"  # Format the new name with leading zeros\n",
    "    old_file = os.path.join(directory, filename)\n",
    "    new_file = os.path.join(directory, new_name)\n",
    "    os.rename(old_file, new_file)\n",
    "\n",
    "print(\"Renaming completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load texts into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "\n",
    "directory = \"db/AMF_selected/\"\n",
    "\n",
    "filenames = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        filenames.append({\"filename\": filename})\n",
    "df = pd.DataFrame(filenames)\n",
    "\n",
    "\n",
    "df[\"text_header\"] = \"\"\n",
    "df[\"N_pages\"] = 0\n",
    "df[\"text_full\"] = \"\"\n",
    "for index, row in df.iterrows():\n",
    "    filepath = os.path.join(directory, row[\"filename\"])\n",
    "\n",
    "    doc = fitz.open(filepath)\n",
    "    text = \"\"\n",
    "    full_text = \"\"\n",
    "\n",
    "    total_pages = len(doc)\n",
    "    df.at[index, \"N_pages\"] = total_pages\n",
    "\n",
    "    header_pages = 3\n",
    "    for page_num in range(total_pages):\n",
    "        page = doc.load_page(page_num)\n",
    "        page_text = page.get_text()\n",
    "        full_text += page_text\n",
    "\n",
    "        # Store text from the first `n_pages` in header_text\n",
    "        if page_num < header_pages:\n",
    "            text += page_text\n",
    "\n",
    "    df.at[index, \"text_header\"] = text\n",
    "    df.at[index, \"text_full\"] = full_text\n",
    "\n",
    "    doc.close()\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get paper title by LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/Users/vahid/Downloads/PhotonicsAI_Project\")\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from PhotonicsAI.Photon import llm_api\n",
    "\n",
    "# sys_prompt = 'Identify the main topics in this document.'\n",
    "sys_prompt = \"Identify and return the title of this document without modifications.\"\n",
    "\n",
    "df[\"title_4omini\"] = \"\"\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    r = llm_api.call_openai(\n",
    "        row[\"text_header\"], sys_prompt=sys_prompt, model=\"gpt-4o-mini\"\n",
    "    )\n",
    "    df.at[index, \"title_4omini\"] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"db/AMF_SelectedPapers.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract pre-templates by LLM (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"/Users/vahid/Downloads/PhotonicsAI_Project\")\n",
    "from PhotonicsAI.Photon import llm_api\n",
    "\n",
    "# df.sort_values(by='filename', inplace=True)\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "# df.to_parquet('db/AMF_SelectedPapers.parquet')\n",
    "\n",
    "\n",
    "df = pd.read_parquet(\"db/AMF_SelectedPapers.parquet\")\n",
    "\n",
    "print(df.loc[0][\"filename\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt0 = \"\"\"This is a scientific article about an integrated photonic circuit.\n",
    "Based on the input article, extract the title of the implemented circuit,\n",
    "the primitive components (these are on-chip components only),\n",
    "the instructions how to assemble the components into the circuit layout,\n",
    "and a short summary of how the chip is modelled or measured.\n",
    "Answer in YAML following the template below.\n",
    "If the paper discusses more than one circuit (e.g. two distinct variations, or a transmitter circuit and a receiver circuit),\n",
    "add them as separate entries in the YAML list.\n",
    "Do not add yaml quote to the output text.\n",
    "\n",
    "Example YAML:\n",
    "Circuit1:\n",
    "    title: wavelength division demultiplexer\n",
    "    components:\n",
    "        - MZI_1 with a delta length of 200 micrometer\n",
    "        - MZI_2 with a delta length of 100 micrometer\n",
    "        - MZI_3 with a delta length of 100 micrometer\n",
    "    assembly_instructions: |\n",
    "        Take three MZIs each with one input ports and two output ports.\n",
    "        Connect one output port of MZI_1 to the input port of MZI_2.\n",
    "        Connect the other output port of MZI_1 to the the input port of MZI_3.\n",
    "    brief_summary: |\n",
    "        The silicon chip is fabricated using deep etch process.\n",
    "        The chip was measured using a 1550 nm pulsed laser source.\"\"\"\n",
    "\n",
    "\n",
    "sys_prompt1 = \"\"\"This scientific article includes some information about a photonic integrated circuit.\n",
    "\n",
    "(Keep Category) I am only interested in the photonic integrated circuit and\n",
    "    - the used material stack,\n",
    "    - the layout design,\n",
    "    - it's building blocks and primitive components,\n",
    "    - how the individual components are connected on chip.\n",
    "\n",
    "(Discard Category) However, the paper probably also include other information that I am not interested in e.g.\n",
    "    - detail methods of nanofabrication,\n",
    "    - engineering of a larger system,\n",
    "    - engineering of any system off-chip,\n",
    "    - how the experiemnt and the measurement were carried out,\n",
    "    - author information, acknowledgements, and references,\n",
    "    - etc.\n",
    "\n",
    "Read the text. Discard any text from Discard Category and keep text related to Keep Category. Do not rephrase anything, just filter it.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# 5, 9, 30\n",
    "# print(df.loc[4]['filename'])\n",
    "r = llm_api.call_openai(\n",
    "    df.loc[0][\"text_full\"], sys_prompt=sys_prompt1, model=\"gpt-4o-mini\"\n",
    ")\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt1 = \"\"\"This is an academic article. Read the text.\n",
    "Does it include any information about a photonic integrated circuit?\n",
    "If yes, find the photonic components that are on the photonic chip.\n",
    "Return a consise list of these photonic components (if any).\n",
    "Output the list in a YAML format. Do not add yaml quote to the output text.\n",
    "\"\"\"\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    r = llm_api.call_openai(\n",
    "        df.loc[i][\"text_full\"], sys_prompt=sys_prompt1, model=\"gpt-4o-mini\"\n",
    "    )\n",
    "    print(i, \"=======================================\")\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df.shape[0]):\n",
    "    r = llm_api.call_openai(\n",
    "        df.loc[i][\"text_full\"], sys_prompt=sys_prompt1, model=\"gpt-4o\"\n",
    "    )\n",
    "    print(i, \"=======================================\")\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "sys_prompt1 = \"\"\"This is an academic article. Read the text.\n",
    "Does it include any information about a photonic integrated circuit?\n",
    "If yes, find the photonic components that are on the photonic chip.\n",
    "Return a consise list of these photonic components (if any).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class ComponentsResponse(BaseModel):\n",
    "    contains_photonic_circuit: bool\n",
    "    components_list: list[str]\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    print(i, \"=======================================\")\n",
    "\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": sys_prompt1},\n",
    "            {\"role\": \"user\", \"content\": df.loc[i][\"text_full\"]},\n",
    "        ],\n",
    "        response_format=ComponentsResponse,\n",
    "    )\n",
    "\n",
    "    message = completion.choices[0].message\n",
    "    if message.parsed:\n",
    "        # print(message.parsed.components)\n",
    "        print(message.parsed.contains_photonic_circuit)\n",
    "        print(\"\\n\".join(message.parsed.components_list))\n",
    "    else:\n",
    "        print(message.refusal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "filepath = \"db/AMF_selected/test2.pdf\"\n",
    "\n",
    "\n",
    "text_full = \"\"\n",
    "doc = fitz.open(filepath)\n",
    "for page_num in range(len(doc)):\n",
    "    page = doc.load_page(page_num)\n",
    "    page_text = page.get_text()\n",
    "    text_full += page_text\n",
    "doc.close()\n",
    "\n",
    "\n",
    "sys_prompt1 = \"\"\"This is a text extracted from an article. Read the text.\n",
    "Is the main topic of this article about an integrated photonic circuit?\n",
    "If yes, find the photonic components that are on the photonic chip.\n",
    "Return a consise list of these photonic components (if any).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class ComponentsResponse(BaseModel):\n",
    "    topic_photonic: bool\n",
    "    components_list: list[str]\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": sys_prompt1},\n",
    "        {\"role\": \"user\", \"content\": text_full},\n",
    "    ],\n",
    "    response_format=ComponentsResponse,\n",
    ")\n",
    "\n",
    "message = completion.choices[0].message\n",
    "if message.parsed:\n",
    "    # print(message.parsed.components)\n",
    "    print(message.parsed.topic_photonic)\n",
    "    print(\"\\n\".join(message.parsed.components_list))\n",
    "else:\n",
    "    print(message.refusal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PhotonEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
