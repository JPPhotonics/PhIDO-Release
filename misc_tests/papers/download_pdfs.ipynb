{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# search and create db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from papersdb import *\n",
    "\n",
    "# https://chatgpt.com/c/a47b4d3e-bafc-419d-b067-eea1cdaa9ceb\n",
    "\n",
    "search_phrases = [\n",
    "    \"Scalability challenges in integrated photonic switch networks\",\n",
    "    \"Low-power design principles for photonic switch circuits\",\n",
    "    \"High-bandwidth photonic switch network design strategies\",\n",
    "    \"Latency optimization in photonic integrated circuits\",\n",
    "    \"Modular design approaches for photonic switch networks\",\n",
    "    \"Crossbar switch topologies in integrated photonic circuits\",\n",
    "    \"Benes network architectures for scalable photonic switching\",\n",
    "    \"Ring resonator-based photonic switch designs and applications\",\n",
    "    \"Multistage network designs for integrated photonic circuits\",\n",
    "    \"Single-mode vs multi-mode photonic switch network designs\",\n",
    "    \"Mode-division multiplexing (MDM) in integrated photonics\",\n",
    "    \"Spatial and wavelength division techniques in photonic switches\",\n",
    "    \"Size and scaling considerations for photonic switch networks\",\n",
    "    \"Miniaturization of photonic integrated circuits for large networks\",\n",
    "    \"Technical specifications and trade-offs in photonic switches\",\n",
    "    \"Insertion loss reduction in integrated photonic switch designs\",\n",
    "    \"Crosstalk mitigation techniques in photonic circuits\",\n",
    "    \"Switching speed optimization in photonic integrated networks\",\n",
    "    \"Extinction ratio enhancement in photonic switch designs\",\n",
    "    \"Waveguide design and optimization for photonic switch networks\",\n",
    "    \"Material choices and trade-offs in photonic switch fabrication\",\n",
    "    \"Silicon photonics-based integrated switch network designs\",\n",
    "    \"MEMS-based photonic switches: design and performance\",\n",
    "    \"Plasmonic components in integrated photonic switch networks\",\n",
    "    \"Thermal tuning mechanisms in ring resonator switches\",\n",
    "    \"Performance vs complexity in photonic switch network design\",\n",
    "    \"AI/ML-based optimization for photonic circuit design\",\n",
    "    \"Hybrid photonic-electronic switch network architectures\",\n",
    "    \"Optical simulation tools for integrated photonic circuits\",\n",
    "    \"Prototyping and testing in photonic switch network development\",\n",
    "    \"Scalable photonic switch networks for data centers\",\n",
    "    \"Design trade-offs in quantum computing with photonic switches\",\n",
    "    \"Case studies of photonic switch networks in high-performance computing\",\n",
    "    \"Future directions in integrated photonic switch network technologies\",\n",
    "    \"Exploration of insertion loss and crosstalk in photonic switches\",\n",
    "    \"Review of waveguide-based photonic switch technologies\",\n",
    "    \"Nonlinear optical effects in photonic switch network design\",\n",
    "]\n",
    "\n",
    "# https://claude.ai/chat/fee274fb-fea4-4ec9-9095-42a656f2f58e\n",
    "wdm_search_phrases = [\n",
    "    \"Integrated photonic wavelength division multiplexer design principles\",\n",
    "    \"WDM circuit design topologies for integrated photonics\",\n",
    "    \"Multi-channel WDM architectures in silicon photonics\",\n",
    "    \"Scaling challenges in integrated photonic WDM devices\",\n",
    "    \"Technical specifications of on-chip wavelength division multiplexers\",\n",
    "    \"Building blocks for integrated photonic WDM circuits\",\n",
    "    \"Arrayed waveguide grating (AWG) design for WDM applications\",\n",
    "    \"Microring resonator-based WDM multiplexers\",\n",
    "    \"Echelle grating multiplexers in integrated photonics\",\n",
    "    \"Mach-Zehnder interferometer WDM designs\",\n",
    "    \"Adiabatic couplers for wavelength division multiplexing\",\n",
    "    \"Fabrication techniques for integrated photonic WDM devices\",\n",
    "    \"Optimization methods for WDM circuit design\",\n",
    "    \"Insertion loss minimization in integrated WDM devices\",\n",
    "    \"Crosstalk reduction techniques in photonic WDM multiplexers\",\n",
    "    \"Thermal stability of integrated photonic WDM circuits\",\n",
    "    \"Broadband WDM multiplexer designs for telecom applications\",\n",
    "    \"Compact WDM devices for data center interconnects\",\n",
    "    \"Polarization-independent WDM multiplexers\",\n",
    "    \"Novel materials for integrated photonic WDM applications\",\n",
    "]\n",
    "\n",
    "\n",
    "# 'integrated silicon photonics switch networks'\n",
    "\n",
    "\n",
    "df = recursive_paper_search(wdm_search_phrases, depth=0, papers_N=800)\n",
    "print(df.info())\n",
    "df.to_parquet(\"db/papers_wdm.parquet\", index=False)\n",
    "# all_papers_df.to_csv('papers.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download open access pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from papersdb import *\n",
    "\n",
    "all_papers_df = pd.read_parquet(\"db/papers_wdm.parquet\")\n",
    "\n",
    "print(\"------ Downloading PDFs\")\n",
    "i = j = 0\n",
    "for index, row in all_papers_df.iterrows():\n",
    "    pdf_url = row[\"openAccessPdf\"]\n",
    "    if pdf_url:  # Check if the PDF URL exists\n",
    "        if os.path.exists(f\"db/pdfs/{row['paperId']}.pdf\"):\n",
    "            i += 1\n",
    "            print(\"file exists!\")\n",
    "        else:\n",
    "            r = download_pdf_requests(pdf_url, \"db/pdfs_wdm\", row[\"paperId\"])\n",
    "            if r is not None:\n",
    "                j += 1\n",
    "            time.sleep(2)  # Adjust sleep time if necessary\n",
    "\n",
    "print(\"====== DONE! ======\")\n",
    "print(\"pdfs already exsited: \", i)\n",
    "print(\"pdfs downloaded\", j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from papersdb import *\n",
    "\n",
    "df = pd.read_parquet(\"papers.parquet\")\n",
    "print(df.shape)\n",
    "# df.info()\n",
    "\n",
    "# df_sorted = df.sort_values(by='influentialCitationCount', ascending=False)\n",
    "# for index, row in df_sorted.head(100).iterrows():\n",
    "#     print(row['influentialCitationCount'], row['url'])\n",
    "\n",
    "arx = 0\n",
    "doi = 0\n",
    "PubMed = 0\n",
    "for index, row in df.iterrows():\n",
    "    externalIds = row[\"externalIds\"]\n",
    "    if externalIds[\"ArXiv\"]:\n",
    "        arx += 1\n",
    "    if externalIds[\"DOI\"]:\n",
    "        doi += 1\n",
    "    if externalIds[\"PubMed\"]:\n",
    "        PubMed += 1\n",
    "\n",
    "print(\"arx\", arx)\n",
    "print(\"doi\", doi)\n",
    "print(\"PubMed\", PubMed)\n",
    "\n",
    "# {'ArXiv': None, 'CorpusId': 125852517, 'DBLP': None, 'DOI': '10.1117/12.2255794', 'MAG': '2582829612', 'PubMed': None, 'PubMedCentral': None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download pdfs by doi link\n",
    "based on the cell above, about 90% of these paper (about switch networks) havd doi links. let's use that to download pdfs.\n",
    "\n",
    "Downloading PDFs proved to be challenging. Many sites are easy for a bot like below, but many others like IEEE and optica block a like this bot. \n",
    "\n",
    "plan:\n",
    "- doi link\n",
    "- arrive at the landing page\n",
    "- save the landing url in the db\n",
    "- download the html page as {html, mhtml, pdf}?\n",
    "- use llm to find the pdf download link\n",
    "- dowanlod pdf\n",
    "\n",
    "Mostly works! \n",
    "Problem: Saving HTML of landing pages is not always reliable because dynamic content like JS changes the links and not valid.\n",
    "possible solutions:\n",
    "- save landing page as mhtml \n",
    "    - none of these python tools can get a mhtml reliably: playwright, pyppeteer, selenium, requests_html. \n",
    "    - since they are mostly in JS, i tried pyppeteer with node. mhtml works pretty well. but it's not loading optica pages!\n",
    "- save landing pages as pdf\n",
    "    - more straightforward\n",
    "    - solves the main issue\n",
    "    - is not as nice as the idea of mhtml!\n",
    "\n",
    "i think for optica and maybe many more, if you know the landing url, you know the pdf url.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# landing_html_url.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "used the script above to save landing pages in html and pdf and add landing url to the parquet df.\n",
    "\n",
    "Now checking the landing urls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"db/papers_wdm.parquet\")\n",
    "print(\"shape of db:\", df.shape)\n",
    "print()\n",
    "\n",
    "df[\"domain\"] = df[\"landing_url\"].apply(lambda x: urlparse(x).netloc)\n",
    "domain_counts = df[\"domain\"].value_counts()\n",
    "\n",
    "print(\"domains:\")\n",
    "print(domain_counts[:20])\n",
    "\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# count how many have DOI, landing url, pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"db/papers_switch.parquet\")\n",
    "\n",
    "i = j = k = l = m = n = o = p = 0\n",
    "for index, row in df.iterrows():\n",
    "    doiurl = row[\"externalIds\"][\"DOI\"]\n",
    "    doi_exist = doiurl is not None\n",
    "    file_exist = os.path.exists(f\"db/pdfs/{row['paperId']}.pdf\")\n",
    "    if not file_exist:\n",
    "        i += 1\n",
    "    if doi_exist:\n",
    "        j += 1\n",
    "    if pd.isna(row[\"landing_url\"]):\n",
    "        k += 1\n",
    "    if doi_exist & (not file_exist):\n",
    "        l += 1\n",
    "    if doi_exist & pd.isna(row[\"landing_url\"]):\n",
    "        m += 1\n",
    "    if doi_exist & (not file_exist) & pd.isna(row[\"landing_url\"]):\n",
    "        n += 1\n",
    "    if row[\"landing_url\"]:\n",
    "        if \"optica.org\" in row[\"landing_url\"]:\n",
    "            o += 1\n",
    "            if not file_exist:\n",
    "                p += 1\n",
    "                # print(row['landing_url'], row['paperId'])\n",
    "                # print()\n",
    "\n",
    "print(\"df shape\", df.shape)\n",
    "print(\"missing pdf files\", i)\n",
    "print(\"doi links\", j)\n",
    "print(\"missing landing urls\", k)\n",
    "print(\"missing pdf but doi exist\", l)\n",
    "print(\"missing landing url but doi exist\", m)\n",
    "print(\"missing landing url, missing file, but doi exist\", n)\n",
    "print(\"optica landing urls\", o)\n",
    "print(\"optica landing urls but pdf missing\", p)\n",
    "# print('pdf files', i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download from IEEE and optica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see ieee_pdf.py\n",
    "\n",
    "# optica_pdf.py doesn't work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download papers that have arxiv id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from papersdb import *\n",
    "\n",
    "df = pd.read_parquet(\"db/papers_wdm.parquet\")\n",
    "\n",
    "print(\"------ Downloading arxiv PDFs\")\n",
    "for index, row in df.iterrows():\n",
    "    ids = row[\"externalIds\"]\n",
    "    arxID = ids[\"ArXiv\"]\n",
    "    if arxID is not None:\n",
    "        if not os.path.exists(f\"db/pdfs/{row['paperId']}.pdf\"):\n",
    "            r = download_pdf_requests(\n",
    "                f\"https://arxiv.org/pdf/{arxID}\", \"db/pdfs\", row[\"paperId\"]\n",
    "            )\n",
    "\n",
    "            df.at[index, \"landing_url\"] = f\"https://arxiv.org/pdf/{arxID}\"\n",
    "            df.to_parquet(\"db/postURL_papers.parquet\", index=False)\n",
    "\n",
    "            time.sleep(10)\n",
    "\n",
    "print(\"====== DONE! ======\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fetch more landing pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader, PdfWriter\n",
    "\n",
    "# Open the original PDF file\n",
    "with open(\"db/6879eb6ad9a2fc1a55a6a07ea2e7a72c8dd642a0.pdf\", \"rb\") as input_pdf_file:\n",
    "    pdf_reader = PdfReader(input_pdf_file)\n",
    "    pdf_writer = PdfWriter()\n",
    "\n",
    "    # Add the first two pages to the writer\n",
    "    if len(pdf_reader.pages) >= 2:\n",
    "        pdf_writer.add_page(pdf_reader.pages[0])\n",
    "        pdf_writer.add_page(pdf_reader.pages[1])\n",
    "    else:\n",
    "        print(\"The PDF does not have two pages.\")\n",
    "\n",
    "    # Save the modified PDF to a new file\n",
    "    with open(\"db/output.pdf\", \"wb\") as output_pdf_file:\n",
    "        pdf_writer.write(output_pdf_file)\n",
    "\n",
    "print(\"The PDF has been processed and saved as 'output.pdf'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from papersdb import *\n",
    "\n",
    "sys.path.append(\"/Users/vahid/Downloads/PhotonicsAI_Project\")\n",
    "from PhotonicsAI.Photon import llm_api\n",
    "\n",
    "# pdf_url = 'https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10131/1013104/The-role-of-integrated-photonics-in-datacenter-networks/10.1117/12.2255794.pdf'\n",
    "# r = download_pdf_with_fallback(pdf_url, 'pdfs', '00000000000000')\n",
    "# print(r)\n",
    "\n",
    "sys_prompt = 'This is a webpage of a scientific article. Can you find a PDF download link? If yes, only return the link with no other information. If no, only return False.\"'\n",
    "# html_content = await save_page_as_html('https://www.doi.org/10.1117/12.2255794', 'example.html')\n",
    "# r = llm_api.call_llm(html_content, sys_prompt, llm_api_selection='gpt-4o-mini')\n",
    "# print(r)\n",
    "\n",
    "all_papers_df = pd.read_parquet(\"papers.parquet\")\n",
    "\n",
    "for index, row in all_papers_df.iterrows():\n",
    "    externalIds = row[\"externalIds\"]\n",
    "    if externalIds[\"DOI\"]:\n",
    "        if os.path.exists(f'pdfs/{row['paperId']}.pdf'):\n",
    "            # print('file exists!')\n",
    "            pass\n",
    "        else:\n",
    "            url = \"https://www.doi.org/\" + externalIds[\"DOI\"]\n",
    "            print(\"____________\")\n",
    "            print(\"DOI:\", url)\n",
    "            html_content, landing_url = await save_page_as_html(\n",
    "                url, f'doihtml/{row['paperId']}.html'\n",
    "            )\n",
    "            if html_content:\n",
    "                print(\"landing url:\", landing_url)\n",
    "                llm_r = llm_api.call_llm(\n",
    "                    html_content, sys_prompt, llm_api_selection=\"gpt-4o-mini\"\n",
    "                )\n",
    "                print(\"pdf link by llm:\", llm_r)\n",
    "                if is_valid_url(llm_r):\n",
    "                    r = download_pdf_requests(llm_r, \"pdfs\", row[\"paperId\"])\n",
    "                else:\n",
    "                    print(\"invalid link?!\")\n",
    "                time.sleep(2)  # Adjust sleep time if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PhotonEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
