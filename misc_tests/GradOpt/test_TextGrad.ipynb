{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textgrad as tg\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../../.env\")\n",
    "\n",
    "tg.set_backward_engine(\"gpt-4o-mini\", override=True)\n",
    "\n",
    "# Step 1: Get an initial response from an LLM.\n",
    "model = tg.BlackboxLLM(\"gpt-4o\")\n",
    "question_string = (\n",
    "    \"If it takes 1 hour to dry 25 shirts under the sun, \"\n",
    "    \"how long will it take to dry 30 shirts under the sun? \"\n",
    "    \"Reason step by step\"\n",
    ")\n",
    "\n",
    "question = tg.Variable(\n",
    "    question_string, role_description=\"question to the LLM\", requires_grad=False\n",
    ")\n",
    "\n",
    "answer = model(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer.set_role_description(\"concise and accurate answer to the question\")\n",
    "# Step 2: Define the loss function and the optimizer, just like in PyTorch!\n",
    "# Here, we don't have SGD, but we have TGD (Textual Gradient Descent)\n",
    "# that works with \"textual gradients\".\n",
    "optimizer = tg.TGD(parameters=[answer])\n",
    "evaluation_instruction = (\n",
    "    f\"Here's a question: {question_string}. \"\n",
    "    \"Evaluate any given answer to this question, \"\n",
    "    \"be smart, logical, and very critical. \"\n",
    "    \"Just provide concise feedback.\"\n",
    ")\n",
    "\n",
    "\n",
    "# TextLoss is a natural-language specified loss function that describes\n",
    "# how we want to evaluate the reasoning.\n",
    "loss_fn = tg.TextLoss(evaluation_instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Do the loss computation, backward pass, and update the punchline.\n",
    "# Exact same syntax as PyTorch!\n",
    "loss = loss_fn(answer)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PhotonEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
