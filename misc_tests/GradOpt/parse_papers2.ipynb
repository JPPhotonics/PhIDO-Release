{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more interesting example. it passes the whole paper and context to optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"C:/Users/vansari/Documents/PhotonicAI\")\n",
    "import pandas as pd\n",
    "import textgrad as tg\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../../.env\")\n",
    "\n",
    "# tg.set_backward_engine(\"gpt-4o\", override=True)\n",
    "llm_engine = tg.get_engine(\"gpt-4o\")\n",
    "tg.set_backward_engine(llm_engine, override=True)\n",
    "\n",
    "\n",
    "# Step 1: Get an initial response from an LLM.\n",
    "df = pd.read_parquet(\"../papers/db/AMF_papers.parquet\")\n",
    "idx = 223\n",
    "article = df.loc[idx][\"text_full\"]\n",
    "print(\"--> filename: \", df.loc[idx][\"filename\"])\n",
    "# 244, 223,\n",
    "\n",
    "problem_text = f\"\"\"Is this a single academic article, and not a dissertation or collection of papers (single_article)?\n",
    "Is the main topic of this article about integrated photonic circuits (topic_photonic)?\n",
    "If yes, find the photonic components that are used on the chip.\n",
    "Return a concise list of these photonic components, if any (components_list).\n",
    "For each component, try to extract: brief spec,\n",
    "and the number of optical input (N) and output (M) ports denoted by NxM, e.g. 1x2.\n",
    "Do not parse specifications and descriptive modifiers of a component as separate components.\n",
    "Finally, is there an enough information to understand and desrcibe how the on-chip components\n",
    "are interconnected to form the photonic circuit (circuit_complete)?\n",
    "Answer in YAML following the template:\n",
    "single_article: True/False\n",
    "topic_photonic: True/False\n",
    "components_list:\n",
    "  - a 1x1 modulator with MHz speed\n",
    "  - a 1x2 component ...\n",
    "  ...\n",
    "circuit_complete: True/False\n",
    "\n",
    "\n",
    "INPUT ARTICLE:\n",
    "{article}\n",
    "\"\"\"\n",
    "\n",
    "problem = tg.Variable(\n",
    "    problem_text, role_description=\"the parsing problem\", requires_grad=False\n",
    ")\n",
    "\n",
    "model = tg.BlackboxLLM(\"gpt-4o\")\n",
    "code = model(problem)\n",
    "\n",
    "print(30 * \"=\" + \"INITIAL ANSWER\")\n",
    "print(code)\n",
    "print(40 * \"=\")\n",
    "print(40 * \"=\")\n",
    "\n",
    "code.set_role_description(\"The yaml code to optimize\")\n",
    "code.requires_grad = True\n",
    "\n",
    "photonic_critic_prompt = \"\"\"You are a smart language model expert in photonic integrated circuits.\n",
    "This YAML file should be an accurate summary of the photonic components presented in the input article.\n",
    "Evaluate components_list in YAML based on:\n",
    "- this should be only a list of photonic components.\n",
    "- it should only represent photonic components on the chip, and not off the chip.\n",
    "- all detail specifications and description of a component should be included for each item.\n",
    "- detail specifications and descriptive modifiers of a component should not be parsed as separate components.\n",
    "- are any photonic components missing?\n",
    "- does YAML follow the provided template?\n",
    "Also evaluate circuit_complete boolean:\n",
    "- is it correct? can you understand and describe the connection between items in components_list?\n",
    "You do not propose a new YAML file, only evaluate the existing YAML file critically and give very concise feedback.\"\"\"\n",
    "loss_system_prompt = tg.Variable(\n",
    "    photonic_critic_prompt,\n",
    "    requires_grad=False,\n",
    "    role_description=\"system prompt to the loss function\",\n",
    ")\n",
    "\n",
    "\n",
    "format_string = \"\"\"Problem: {problem}\\nCurrent YAML code: {code}\"\"\"\n",
    "\n",
    "fields = {\"problem\": None, \"code\": None}\n",
    "formatted_llm_call = tg.autograd.FormattedLLMCall(\n",
    "    engine=llm_engine,\n",
    "    format_string=format_string,\n",
    "    fields=fields,\n",
    "    system_prompt=loss_system_prompt,\n",
    ")\n",
    "\n",
    "\n",
    "# Finally, the loss function\n",
    "def loss_fn(problem: tg.Variable, code: tg.Variable) -> tg.Variable:\n",
    "    inputs = {\"problem\": problem, \"code\": code}\n",
    "\n",
    "    return formatted_llm_call(\n",
    "        inputs=inputs,\n",
    "        response_role_description=f\"evaluation of the {code.get_role_description()}\",\n",
    "    )\n",
    "\n",
    "\n",
    "loss = loss_fn(problem, code)\n",
    "print(30 * \"=\" + \"LOSS\")\n",
    "print(loss.value)\n",
    "loss.backward()\n",
    "\n",
    "print(30 * \"=\" + \"CODE GRAD\")\n",
    "print(code.gradients)\n",
    "\n",
    "optimizer = tg.TGD(parameters=[code])\n",
    "optimizer.step()\n",
    "print(30 * \"=\" + \"UPDATED CODE\")\n",
    "print(code.value)\n",
    "print(30 * \"=\")\n",
    "code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.generate_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "loss = loss_fn(problem, code)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "print(code.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "loss = loss_fn(problem, code)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "print(code.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "loss = loss_fn(problem, code)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "print(code.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "loss = loss_fn(problem, code)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "print(code.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PhotonEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
