{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simple example. it doesn't pass the whole paper and context to optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"C:/Users/vansari/Documents/PhotonicAI\")\n",
    "import pandas as pd\n",
    "import textgrad as tg\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../../.env\")\n",
    "\n",
    "tg.set_backward_engine(\"gpt-4o\", override=True)\n",
    "# tg.set_backward_engine(\"gpt-4o-mini\", override=True)\n",
    "# tg.set_backward_engine(tg.get_engine(\"gpt-3.5-turbo\"))\n",
    "\n",
    "# Step 1: Get an initial response from an LLM.\n",
    "df = pd.read_parquet(\"../papers/db/AMF_papers.parquet\")\n",
    "idx = 223\n",
    "article = df.loc[idx][\"text_full\"]\n",
    "print(\"--> filename: \", df.loc[idx][\"filename\"])\n",
    "# 244, 223,\n",
    "\n",
    "question_string = f\"\"\"Is this a single academic article, and not a dissertation or collection of papers (single_article)?\n",
    "Is the main topic of this article about integrated photonic circuits (topic_photonic)?\n",
    "If yes, find the photonic components that are used on the chip.\n",
    "Return a concise list of these photonic components, if any (components_list).\n",
    "For each component, try to extract: brief spec,\n",
    "and the number of optical input (N) and output (M) ports denoted by NxM, e.g. 1x2.\n",
    "Finally, is there an enough information to understand and desrcibe how the on-chip components\n",
    "are interconnected to form the photonic circuit (circuit_complete)?\n",
    "Answer in YAML following the template:\n",
    "single_article: True/False\n",
    "topic_photonic: True/False\n",
    "components_list:\n",
    "  - a 1x1 modulator with MHz speed\n",
    "  - a 1x2 component ...\n",
    "  ...\n",
    "circuit_complete: True/False\n",
    "\n",
    "\n",
    "INPUT ARTICLE:\n",
    "{article}\n",
    "\"\"\"\n",
    "\n",
    "question = tg.Variable(\n",
    "    question_string, role_description=\"question to the LLM\", requires_grad=False\n",
    ")\n",
    "\n",
    "model = tg.BlackboxLLM(\"gpt-4o\")\n",
    "answer = model(question)\n",
    "\n",
    "print(30 * \"=\" + \"INITIAL ANSWER\")\n",
    "print(answer)\n",
    "print(40 * \"=\")\n",
    "print(40 * \"=\")\n",
    "\n",
    "photonic_critic_prompt = \"\"\"You are a smart language model expert in photonic integrated circuits.\n",
    "This YAML file should be an accurate summary of the photonic components presented in the input article.\n",
    "Evaluate components_list in YAML based on:\n",
    "- it should only represent photonic components on the chip, and not off the chip.\n",
    "- does it accurately represent the photonic components?\n",
    "- is any photonic component missing?\n",
    "- this should be only a list of photonic components.\n",
    "- does YAML follow the provided template?\n",
    "Also evaluate circuit_complete boolean:\n",
    "- is it correct? can you understand and describe the connection between items in components_list?\n",
    "You do not propose a new YAML file, only evaluate the existing YAML file critically and give very concise feedback.\"\"\"\n",
    "loss_system_prompt = tg.Variable(\n",
    "    photonic_critic_prompt,\n",
    "    requires_grad=False,\n",
    "    role_description=\"system prompt to the loss function\",\n",
    ")\n",
    "\n",
    "\n",
    "# x = tg.Variable(str(answer), role_description='The yaml file to optimize', requires_grad=True)\n",
    "answer.set_role_description(\"The yaml file to optimize\")\n",
    "answer.requires_grad = True\n",
    "\n",
    "# system_prompt = tg.Variable(\"Evaluate the correctness of this sentence\", role_description=\"The system prompt\")\n",
    "loss_fn = tg.TextLoss(loss_system_prompt)\n",
    "\n",
    "\n",
    "loss = loss_fn(answer)\n",
    "print(30 * \"=\" + \"LOSS\")\n",
    "print(loss)\n",
    "loss.backward()\n",
    "optimizer = tg.TGD(parameters=[answer], verbose=False)\n",
    "optimizer.step()\n",
    "print(30 * \"=\" + \"UPDATED ANSWER\")\n",
    "print(answer.value)\n",
    "print(30 * \"=\")\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.generate_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run optimizer again...\n",
    "optimizer.zero_grad()\n",
    "loss = loss_fn(answer)\n",
    "loss.backward()\n",
    "optimizer = tg.TGD(parameters=[answer], verbose=False)\n",
    "optimizer.step()\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PhotonEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
